{"cells":[{"cell_type":"code","source":["# Load data"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["%fs ls FileStore/tables/dict.csv"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["%sql DROP TABLE IF EXISTS vehicle_process"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["#Create table"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["%sql\n\nCREATE TABLE vehicle_process (\n  Photo_Name STRING,\n  Left DOUBLE,\n  Top DOUBLE,\n  Right DOUBLE,\n  Bottom DOUBLE,\n  Vehicle_Type STRING)\nUSING com.databricks.spark.csv\nOPTIONS (path \"FileStore/tables/dict.csv\", header \"true\")"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["vehicles = spark.table(\"vehicle_process\")\ncols = vehicles.columns"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["display(vehicles)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["#Preprocess Data"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["# Using One-Hot Encoding"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["from pyspark.ml import Pipeline\nfrom pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n\ncategoricalColumns = [\"Photo_Name\",\"Vehicle_Type\"]\nstages = [] \nfor categoricalCol in categoricalColumns:\n  stringIndexer = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol+\"Index\")\n  encoder = OneHotEncoder(inputCol=categoricalCol+\"Index\", outputCol=categoricalCol+\"classVec\")\n  stages += [stringIndexer, encoder]"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["label_stringIdx = StringIndexer(inputCol = \"Vehicle_Type\", outputCol = \"label\")\nstages += [label_stringIdx]"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["numericCols = [\"Left\", \"Top\", \"Right\", \"Bottom\"]\nassemblerInputs = map(lambda c: c + \"classVec\", categoricalColumns) + numericCols\nassembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\nstages += [assembler]"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["pipeline = Pipeline(stages=stages)\n\npipelineModel = pipeline.fit(vehicles)\nvehicles = pipelineModel.transform(vehicles)\n\nselectedcols = [\"label\", \"features\"] + cols\nvehicles = vehicles.select(selectedcols)\ndisplay(vehicles)"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["# Randomly split data into training and test sets. set seed for reproducibility"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["(trainingData, testData) = vehicles.randomSplit([0.7, 0.3], seed = 100)\nprint trainingData.count()\nprint testData.count()"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["# Fit and Evaluate Models"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["# Logistic Regression"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["# Create initial LogisticRegression model"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["from pyspark.ml.classification import LogisticRegression\n\nlr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=10)\n\nlrModel = lr.fit(trainingData)"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["predictions = lrModel.transform(testData)"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["predictions.printSchema()"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["selected = predictions.select(\"label\", \"prediction\", \"probability\", \"Left\", \"Vehicle_Type\")\ndisplay(selected)"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator\n\nevaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\nevaluator.evaluate(predictions)"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["evaluator.getMetricName()"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["print lr.explainParams()"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\nparamGrid = (ParamGridBuilder()\n             .addGrid(lr.regParam, [0.01, 0.5, 2.0])\n             .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\n             .addGrid(lr.maxIter, [1, 5, 10])\n             .build())"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["# Create 5-fold CrossValidator and Run cross validations"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["cv = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n\ncvModel = cv.fit(trainingData)"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["predictions = cvModel.transform(testData)"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["evaluator.evaluate(predictions)"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["print 'Model Intercept: ', cvModel.bestModel.interceptVector"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["weights = cvModel.bestModel.coefficientMatrix\n\nweights = map(lambda w: (float(w),), weights) \nweightsDF = sqlContext.createDataFrame(weights, [\"Feature Weight\"])\ndisplay(weightsDF)"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"code","source":["selected = predictions.select(\"label\", \"prediction\", \"probability\", \"Left\", \"Vehicle_Type\")\ndisplay(selected)"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"code","source":["# Decision Trees"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"code","source":["# Create  Decision Tree Model"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"code","source":["from pyspark.ml.classification import DecisionTreeClassifier\n\ndt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\", maxDepth=3)\n\ndtModel = dt.fit(trainingData)"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"code","source":["print \"numNodes = \", dtModel.numNodes\nprint \"depth = \", dtModel.depth"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"code","source":["predictions = dtModel.transform(testData)"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"code","source":["predictions.printSchema()"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"code","source":["selected = predictions.select(\"label\", \"prediction\", \"probability\", \"Left\", \"Vehicle_Type\")\ndisplay(selected)"],"metadata":{},"outputs":[],"execution_count":40},{"cell_type":"code","source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator\n\nevaluator = BinaryClassificationEvaluator()\nevaluator.evaluate(predictions)"],"metadata":{},"outputs":[],"execution_count":41},{"cell_type":"code","source":["dt.getImpurity()"],"metadata":{},"outputs":[],"execution_count":42},{"cell_type":"code","source":["from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\nparamGrid = (ParamGridBuilder()\n             .addGrid(dt.maxDepth, [1,2,6,10])\n             .addGrid(dt.maxBins, [20,40,80])\n             .build())"],"metadata":{},"outputs":[],"execution_count":43},{"cell_type":"code","source":["cv = CrossValidator(estimator=dt, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n\ncvModel = cv.fit(trainingData)"],"metadata":{},"outputs":[],"execution_count":44},{"cell_type":"code","source":["print \"numNodes = \", cvModel.bestModel.numNodes\nprint \"depth = \", cvModel.bestModel.depth"],"metadata":{},"outputs":[],"execution_count":45},{"cell_type":"code","source":["predictions = cvModel.transform(testData)"],"metadata":{},"outputs":[],"execution_count":46},{"cell_type":"code","source":["evaluator.evaluate(predictions)"],"metadata":{},"outputs":[],"execution_count":47},{"cell_type":"code","source":["selected = predictions.select(\"label\", \"prediction\", \"probability\", \"Left\", \"Vehicle_Type\")\ndisplay(selected)"],"metadata":{},"outputs":[],"execution_count":48},{"cell_type":"code","source":["# Random Forest"],"metadata":{},"outputs":[],"execution_count":49},{"cell_type":"code","source":["# Create  RandomForest model"],"metadata":{},"outputs":[],"execution_count":50},{"cell_type":"code","source":["from pyspark.ml.classification import RandomForestClassifier\n\nrf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n\nrfModel = rf.fit(trainingData)"],"metadata":{},"outputs":[],"execution_count":51},{"cell_type":"code","source":["predictions = rfModel.transform(testData)"],"metadata":{},"outputs":[],"execution_count":52},{"cell_type":"code","source":["predictions.printSchema()"],"metadata":{},"outputs":[],"execution_count":53},{"cell_type":"code","source":["selected = predictions.select(\"label\", \"prediction\", \"probability\", \"Left\", \"Vehicle_Type\")\ndisplay(selected)"],"metadata":{},"outputs":[],"execution_count":54},{"cell_type":"code","source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator\n\nevaluator = BinaryClassificationEvaluator()\nevaluator.evaluate(predictions)"],"metadata":{},"outputs":[],"execution_count":55},{"cell_type":"code","source":["from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\nparamGrid = (ParamGridBuilder()\n             .addGrid(rf.maxDepth, [2, 4, 6])\n             .addGrid(rf.maxBins, [20, 60])\n             .addGrid(rf.numTrees, [5, 20])\n             .build())"],"metadata":{},"outputs":[],"execution_count":56},{"cell_type":"code","source":["cv = CrossValidator(estimator=rf, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n\ncvModel = cv.fit(trainingData)"],"metadata":{},"outputs":[],"execution_count":57},{"cell_type":"code","source":["predictions = cvModel.transform(testData)"],"metadata":{},"outputs":[],"execution_count":58},{"cell_type":"code","source":["evaluator.evaluate(predictions)"],"metadata":{},"outputs":[],"execution_count":59},{"cell_type":"code","source":["selected = predictions.select(\"label\", \"prediction\", \"probability\", \"Left\", \"Vehicle_Type\")\ndisplay(selected)"],"metadata":{},"outputs":[],"execution_count":60},{"cell_type":"code","source":["# Make Predictions"],"metadata":{},"outputs":[],"execution_count":61},{"cell_type":"code","source":["bestModel = cvModel.bestModel"],"metadata":{},"outputs":[],"execution_count":62},{"cell_type":"code","source":["finalPredictions = bestModel.transform(vehicles)"],"metadata":{},"outputs":[],"execution_count":63},{"cell_type":"code","source":["evaluator.evaluate(finalPredictions)"],"metadata":{},"outputs":[],"execution_count":64},{"cell_type":"code","source":["finalPredictions.createOrReplaceTempView(\"finalPredictions\")"],"metadata":{},"outputs":[],"execution_count":65}],"metadata":{"name":"PartC_1","notebookId":4326740951875551},"nbformat":4,"nbformat_minor":0}
